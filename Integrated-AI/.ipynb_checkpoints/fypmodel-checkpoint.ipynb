{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c9c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 02:24:47.291990: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-05 02:24:47.668388: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-05 02:24:47.669461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-05 02:24:49.551055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import models, layers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da351c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('XSS_dataset.csv', encoding='utf-8-sig')\n",
    "X = df['Sentence']\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71dc07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a57a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10948, 5640)\n",
      "(10948,)\n",
      "(2738, 5640)\n",
      "(2738,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df = 2, max_df = 0.8, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X.values.astype('U')).toarray()\n",
    "#these above 1 lines variabel .astype\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc2115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression on test set : 0.9985390796201608\n",
      "F1 Score of Logistic Regression on test set : 0.9986101459346769\n",
      "sensitivity= 0.9979166666666667\n",
      "specificity= 0.9992295839753467\n",
      "Precision= 0.9993045897079277\n"
     ]
    }
   ],
   "source": [
    "m1 = LogisticRegression()\n",
    "m1.fit(X_train, y_train)\n",
    "y_pred = m1.predict(X_test)\n",
    "print(f\"Accuracy of Logistic Regression on test set : {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"F1 Score of Logistic Regression on test set : {f1_score(y_pred, y_test)}\")\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(\"sensitivity=\",sensitivity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity=\",specificity)\n",
    "\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"Precision=\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af61887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6267420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of AadaBoost on test set : 0.9992695398100804\n",
      "F1 Score of AadaBoost on test set : 0.9993050729673384\n",
      "sensitivity= 0.9986111111111111\n",
      "specificity= 1.0\n",
      "Precision= 1.0\n"
     ]
    }
   ],
   "source": [
    "m2 = AdaBoostClassifier(n_estimators=100)\n",
    "m2.fit(X_train, y_train)\n",
    "y_pred = m2.predict(X_test)\n",
    "print(f\"Accuracy of AadaBoost on test set : {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"F1 Score of AadaBoost on test set : {f1_score(y_pred, y_test)}\")\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(\"sensitivity=\",sensitivity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity=\",specificity)\n",
    "\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"Precision=\",Precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b87e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes on test set : 0.8889700511322133\n",
      "F1 Score of Naive Bayes on test set : 0.9044626021370208\n",
      "sensitivity= 0.9993055555555556\n",
      "specificity= 0.7665639445300462\n",
      "Precision= 0.8260619977037887\n"
     ]
    }
   ],
   "source": [
    "m3 = GaussianNB()\n",
    "m3.fit(X_train, y_train)\n",
    "y_pred = m3.predict(X_test)\n",
    "print(f\"Accuracy of Naive Bayes on test set : {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"F1 Score of Naive Bayes on test set : {f1_score(y_pred, y_test)}\")\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(\"sensitivity=\",sensitivity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity=\",specificity)\n",
    "\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"Precision=\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603ef1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45205791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost on test set : 0.9970781592403214\n",
      "F1 Score of XGBoost on test set : 0.9972183588317107\n",
      "sensitivity= 0.9958333333333333\n",
      "specificity= 0.9984591679506933\n",
      "Precision= 0.9986072423398329\n"
     ]
    }
   ],
   "source": [
    "m4 = xgb.XGBClassifier(n_estimators=100)\n",
    "m4.fit(X_train, y_train)\n",
    "y_pred = m4.predict(X_test)\n",
    "print(f\"Accuracy of XGBoost on test set : {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"F1 Score of XGBoost on test set : {f1_score(y_pred, y_test)}\")\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(\"sensitivity=\",sensitivity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity=\",specificity)\n",
    "\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"Precision=\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8509630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9ebc934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree on test set : 0.9989043097151206\n",
      "F1 Score of Decision Tree on test set : 0.9989579715178881\n",
      "sensitivity= 0.9986111111111111\n",
      "specificity= 0.9992295839753467\n",
      "Precision= 0.9993050729673384\n"
     ]
    }
   ],
   "source": [
    "m5 = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "m5.fit(X_train, y_train)\n",
    "y_pred = m5.predict(X_test)\n",
    "print(f\"Accuracy of Decision Tree on test set : {accuracy_score(y_pred, y_test)}\")\n",
    "print(f\"F1 Score of Decision Tree on test set : {f1_score(y_pred, y_test)}\")\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(\"sensitivity=\",sensitivity)\n",
    "specificity = TN / (TN + FP)\n",
    "print(\"specificity=\",specificity)\n",
    "\n",
    "\n",
    "Precision = TP / float(TP + FP)\n",
    "Recall = TP / float(TP + FN)\n",
    "F1 = 2*((Precision*Recall)/(Precision+Recall))\n",
    "print (\"Precision=\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9f5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename1 = 'm1.sav'\n",
    "filename2 = 'm2.sav'\n",
    "filename3 = 'm3.sav'\n",
    "filename4 = 'm4.sav'\n",
    "filename5 = 'm5.sav'\n",
    "pickle.dump(m1, open(\"m1.sav\", 'wb'))\n",
    "pickle.dump(m2, open(\"m2.sav\", 'wb'))\n",
    "pickle.dump(m3, open(\"m3.sav\", 'wb'))\n",
    "pickle.dump(m4, open(\"m4.sav\", 'wb'))\n",
    "pickle.dump(m5, open(\"m5.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9aff15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10948, 5640)\n",
      "(10948,)\n",
      "(2738, 5640)\n",
      "(2738,)\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#start from here after training \n",
    "import pickle\n",
    "m1 = pickle.load(open(\"m1.sav\", 'rb'))\n",
    "m2 = pickle.load(open(\"m2.sav\", 'rb'))\n",
    "m3 = pickle.load(open(\"m3.sav\", 'rb'))\n",
    "m4 = pickle.load(open(\"m4.sav\", 'rb'))\n",
    "m5 = pickle.load(open(\"m5.sav\", 'rb'))\n",
    "\n",
    "sqlvb2 = [\"hello\"]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import models, layers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('XSS_dataset.csv', encoding='utf-8-sig')\n",
    "X = df['Sentence']\n",
    "y = df['Label']\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "vectorizer = CountVectorizer(min_df = 2, max_df = 0.8, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X.values.astype('U')).toarray()\n",
    "#these above 1 lines variabel .astype\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "s = vectorizer.transform(sqlvb2).toarray()\n",
    "m1_pred = m1.predict(s)\n",
    "m2_pred = m2.predict(s)\n",
    "m3_pred = m3.predict(s)\n",
    "m4_pred = m4.predict(s)\n",
    "m5_pred = m5.predict(s)\n",
    "print(m1_pred)\n",
    "print(m2_pred)\n",
    "print(m3_pred)\n",
    "print(m4_pred)\n",
    "print(m5_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77929501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[(41, 'AI', 'is', 'now', 'Connected')]\n",
      "41\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(42, 'aasd', 'asd', 'asd', 'asd')]\n",
      "42\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[0]\n",
      "[0]\n",
      "[1]\n",
      "[0]\n",
      "[0]\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(43, 'aasd', 'asd', 'vartempattack', 'asd')]\n",
      "43\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n",
      "[(44, 'aasd', 'asd', \"<tt onmouseover='alert(1)'>test</tt>\", 'asd')]\n",
      "44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m         cnx\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m mysql\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errorcode\u001b[38;5;241m.\u001b[39mER_ACCESS_DENIED_ERROR:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import time\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "cnx = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"puser\",\n",
    "    password=\"password\",\n",
    "    database=\"fyp\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# Define the INSERT statement\n",
    "query = \"INSERT INTO logs (source_IP, dest_IP, payload,attack) VALUES (%s, %s, %s,%s)\"\n",
    "\n",
    "\n",
    "# Define the values to be inserted\n",
    "values = (\"AI\", \"is\", \"now\",\"Connected\")\n",
    "\n",
    "# Execute the INSERT statement\n",
    "cursor.execute(query, values)\n",
    "\n",
    "# Commit the changes to the daatbase\n",
    "cnx.commit()\n",
    "\n",
    "\n",
    "\n",
    "# Define the INSERT statement\n",
    "query = \"select * from logs;\"\n",
    "\n",
    "query = \"drop table ailogs\";\n",
    "cursor.execute(query)\n",
    "query = \"CREATE TABLE ailogs (id INT AUTO_INCREMENT PRIMARY KEY, LogisticRegression INT, AdaBoostClassifier INT, GaussianNB INT, XGBClassifier INT, DecisionTreeClassifier INT,total int);\"\n",
    "\n",
    "\n",
    "# Execute the INSERT statement\n",
    "cursor.execute(query)\n",
    "\n",
    "\n",
    "\n",
    "# Close the cursor and connection objects\n",
    "#cursor.close()\n",
    "#cnx.close()\n",
    "sqlvb2 = [\"hello\"]\n",
    "s = vectorizer.transform(sqlvb2).toarray()\n",
    "m1_pred = m1.predict(s)\n",
    "m2_pred = m2.predict(s)\n",
    "m3_pred = m3.predict(s)\n",
    "m4_pred = m4.predict(s)\n",
    "m5_pred = m5.predict(s)\n",
    "print(m1_pred)\n",
    "print(m2_pred)\n",
    "print(m3_pred)\n",
    "print(m4_pred)\n",
    "print(m5_pred)\n",
    "\n",
    "query = \"SELECT * FROM logs ORDER BY id DESC LIMIT 1;\"\n",
    "cursor.execute(query)\n",
    "row = cursor.fetchall()\n",
    "print(row)\n",
    "update = (row[0])[0]\n",
    "\n",
    "passed=1\n",
    "\n",
    "while(1):\n",
    "    try:\n",
    "        cnx = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"puser\",\n",
    "        password=\"password\",\n",
    "        database=\"fyp\"\n",
    "        )\n",
    "        # create cursor object\n",
    "        cursor = cnx.cursor()\n",
    "        query = \"SELECT * FROM logs ORDER BY id DESC LIMIT 1;\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchall()\n",
    "        print(row)\n",
    "        update = (row[0])[0]\n",
    "        print(update)\n",
    "        if update != passed:\n",
    "            passed=update\n",
    "            sqlvb2 = [(row[0])[3]]\n",
    "            s = vectorizer.transform(sqlvb2).toarray()\n",
    "            m1_pred = m1.predict(s)\n",
    "            m2_pred = m2.predict(s)\n",
    "            m3_pred = m3.predict(s)\n",
    "            m4_pred = m4.predict(s)\n",
    "            m5_pred = m5.predict(s)\n",
    "            print(m1_pred)\n",
    "            print(m2_pred)\n",
    "            print(m3_pred)\n",
    "            print(m4_pred)\n",
    "            print(m5_pred)\n",
    "            t=m1_pred+m2_pred+m3_pred+m4_pred+m5_pred\n",
    "            query = \"INSERT INTO ailogs (LogisticRegression, AdaBoostClassifier, GaussianNB, XGBClassifier, DecisionTreeClassifier, total) VALUES (%s, %s, %s, %s, %s, %s);\"\n",
    "            # Define the values to be inserted\n",
    "            values = (int(m1_pred[0]), int(m2_pred[0]), int(m3_pred[0]), int(m4_pred[0]), int(m5_pred[0]), t)\n",
    "            # Execute the INSERT statement\n",
    "            cursor.execute(query, values)\n",
    "            # Commit the changes to the daatbase\n",
    "            cnx.commit()\n",
    "        else:\n",
    "            time.sleep(2)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "            print(\"Something is wrong with your user name or password\")\n",
    "        elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            print(\"Database does not exist\")\n",
    "        elif err.errno == errorcode.CR_CONN_HOST_ERROR:\n",
    "            print(\"Connection error\")\n",
    "        elif err.errno == errorcode.CR_CONN_HOST_ERROR:\n",
    "            print(\"Connection error\")\n",
    "        elif err.errno == errorcode.CR_SERVER_LOST:\n",
    "            print(\"Connection lost, retrying\")\n",
    "            cnx.close()\n",
    "        else:\n",
    "            print(err)\n",
    "        time.sleep(2) # sleep before attempting to reconnect\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf61d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
